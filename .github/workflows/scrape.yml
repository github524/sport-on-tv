name: Scrape TV Listings

permissions:
  contents: write

on:
  schedule:
    - cron: "0 7 * * *"   # 7 AM GMT
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      # 1. Checkout the repo with full history
      - uses: actions/checkout@v4
        with:
          persist-credentials: true
          fetch-depth: 0

      # 2. Set up Python
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # 3. Install dependencies
      - run: pip install requests beautifulsoup4

      # 4. Run the scraper
      - run: python scraper/scrape_wtm.py

      # 5. Ensure tv_schedule.json exists
      - run: |
          if [ ! -f tv_schedule.json ]; then
            echo '{"status": "placeholder", "generated_at": null}' > tv_schedule.json
          fi

      # 6. Sync with remote, commit, and push
      - run: |
          git config user.name "github-actions"
          git config user.email "github-actions@github.com"

          # Pull remote changes and rebase
          git pull --rebase origin main || echo "No remote changes to pull"

          # Add and commit changes
          git add tv_schedule.json
          git commit -m "Update TV schedule" || echo "No changes"

          # Push changes
          git push origin main
