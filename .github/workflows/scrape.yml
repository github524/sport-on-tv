name: Scrape TV Listings

permissions:
  contents: write

on:
  schedule:
    - cron: "0 7 * * *"   # daily at 07:00 UTC (7 AM GMT)
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      # 1. Checkout the repo with full history and credentials
      - uses: actions/checkout@v4
        with:
          persist-credentials: true
          fetch-depth: 0

      # 2. Set up Python
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # 3. Install scraper dependencies
      - run: pip install requests beautifulsoup4

      # 4. Run the scraper
      - run: python scraper/scrape_wtm.py

      # 5. Ensure tv_schedule.json exists
      - run: |
          if [ ! -f tv_schedule.json ]; then
            echo '{"status": "placeholder", "generated_at": null}' > tv_schedule.json
          fi

      # 6. Commit and push safely with remote sync
      - run: |
          git config user.name "github-actions"
          git config user.email "github-actions@github.com"

          # Fetch remote changes and reset local branch to match remote
          git fetch origin main
          git reset --soft origin/main

          # Stage and commit changes
          git add tv_schedule.json
          git commit -m "Update TV schedule" || echo "No changes"

          # Push updates to main branch
          git push origin main
